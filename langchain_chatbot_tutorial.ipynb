{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdw223/langchain_chatbot/blob/main/langchain_chatbot_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Chatbot Tutorial ü§ñ\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Welcome to this beginner-friendly tutorial on building a chatbot with LangChain and LangGraph!\n",
        "\n",
        "## What you'll learn:\n",
        "- How to set up a simple AI chatbot\n",
        "- Understanding the basic components of LangChain/LangGraph\n",
        "- How to interact with Google's Gemini AI model\n",
        "- Building a conversational flow\n",
        "\n",
        "## Prerequisites:\n",
        "- No prior Python knowledge required! We'll explain everything step by step\n",
        "- A Google API key (we'll show you how to get one)\n",
        "\n",
        "Let's get started! üöÄ\n"
      ],
      "metadata": {
        "id": "RGmAQeZuQArO"
      }
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "osEQKHmZMJfn"
      },
      "source": [
        "Step 1: Getting Your Google API Key üîë\n",
        "\n",
        "Before we start coding, you'll need a Google API key to use the Gemini AI model.\n",
        "\n",
        "How to get your API key:\n",
        "1. Go to [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
        "2. Sign in with your Google account\n",
        "3. Click \"Create API Key\"\n",
        "4. Copy the key (keep it safe!)\n",
        "\n",
        "Important Notes:\n",
        "- ‚ö†Ô∏è **Never share your API key publicly**\n",
        "- ‚ö†Ô∏è **Don't commit it to GitHub or other public repositories**\n",
        "- üí° **Tip**: You can use Google AI Studio for free with rate limits\n",
        "\n",
        "Once you have your key, we'll show you how to use it safely!\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Hl3foULiMJfo"
      },
      "source": [
        "Step 2: Install Required Packages üì¶\n",
        "\n",
        "First, we need to install the packages that our chatbot will use. Think of these as tools in a toolbox - each one has a specific job!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IPCv51uxMJfo",
        "outputId": "c7faee8d-439d-4887-a44c-0c0a26c23818",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.13-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.14 in /usr/local/lib/python3.12/dist-packages (from langchain-tavily) (3.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.76.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.12-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.11-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading langchain_tavily-0.2.10-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading langchain_tavily-0.2.9-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.8-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.7-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.6-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.5-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.4-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting mypy<2.0.0,>=1.15.0 (from langchain-tavily)\n",
            "  Downloading mypy-1.18.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting langchain-tavily\n",
            "  Downloading langchain_tavily-0.2.3-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.2-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.1-py3-none-any.whl.metadata (21 kB)\n",
            "  Downloading langchain_tavily-0.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "  Downloading langchain_tavily-0.1.6-py3-none-any.whl.metadata (11 kB)\n",
            "  Downloading langchain_tavily-0.1.5-py3-none-any.whl.metadata (11 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai) (0.8.5)\n",
            "  Downloading langchain_google_genai-2.0.9-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.8-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/ff/f5/973de330f4647f18b877f939a73f4ea6b0de5606bf563be486eee632fe84/langchain_google_genai-2.0.4-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading langchain_google_genai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-2.0.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.9-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.6-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-generativeai<0.6.0,>=0.5.2 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-1.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting google-generativeai<0.5.0,>=0.4.1 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.11-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading langchain_google_genai-0.0.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-generativeai<0.4.0,>=0.3.1 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-0.0.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_google_genai-0.0.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_google_genai-0.0.6-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_google_genai-0.0.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_google_genai-0.0.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Downloading langchain_google_genai-0.0.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/b1/3c/acc0956a0da96b25a2c5c1a85168eacf1253639a04ed391d7a7bcaae5d6c/langgraph-1.0.1-py3-none-any.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.72.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
            "Downloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tavily-0.2.13-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, langgraph-sdk, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-google-genai, langgraph, langchain-tavily\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.9.0 langchain-google-genai-2.1.12 langchain-tavily-0.2.13 langgraph-1.0.1 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4d23f603b5c64613b47832b8780e33d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Installation complete! Ready to build our chatbot.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "# This might take a few minutes the first time you run it\n",
        "\n",
        "%pip install langchain langgraph langchain-google-genai langchain-tavily\n",
        "\n",
        "print(\"‚úÖ Installation complete! Ready to build our chatbot.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "aRicUAstMJfp"
      },
      "source": [
        "Step 3: Set Up Your API Key üîê\n",
        "\n",
        "Now we'll set up your Google API key. Replace `\"your_api_key_here\"` with the actual key you got from Google AI Studio.\n",
        "\n",
        "**Important**: This is just for learning purposes. In a real application, you'd store this more securely!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sWze2cNpMJfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602aad10-a94d-4613-8fcc-38c57b93349e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key is set up!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Replace \"your_api_key_here\" with your actual Google API key\n",
        "# Make sure to keep the quotes around it!\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"your_api_key_here\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "# This line checks if the key was set correctly\n",
        "if os.environ.get(\"GOOGLE_API_KEY\") == \"your_api_key_here\":\n",
        "    print(\"‚ö†Ô∏è  Don't forget to replace 'your_api_key_here' with your actual API key!\")\n",
        "else:\n",
        "    print(\"‚úÖ API key is set up!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "DbyTqQ7PMJfp"
      },
      "source": [
        "Step 4: Import the Tools We Need üõ†Ô∏è\n",
        "\n",
        "Now let's import all the tools (libraries) we'll use to build our chatbot. Think of this like gathering all your ingredients before cooking!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E_0sm8kTMJfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e91dfc5-967c-4f87-ac95-8262a4f192e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All tools imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import statements - these bring in the tools we need\n",
        "from typing import Annotated                      # Helps with type hints (optional but good practice)\n",
        "from typing_extensions import TypedDict           # Helps us define data structures\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END    # The main graph components\n",
        "from langgraph.graph.message import add_messages      # Handles message management\n",
        "from langchain.chat_models import init_chat_model     # Connects to AI models\n",
        "\n",
        "print(\"‚úÖ All tools imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "kS8Xp6dZMJfq"
      },
      "source": [
        "Step 5: Define the State Structure üìã\n",
        "\n",
        "In LangGraph, we need to define what information our chatbot will keep track of. Think of this as the chatbot's \"memory\" structure.\n",
        "\n",
        "For our chatbot, we only need to remember the conversation messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KU0KS3GFMJfq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74161495-2fa3-4117-f684-b913d91358ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ State structure defined!\n",
            "Our chatbot will remember: messages in the conversation\n"
          ]
        }
      ],
      "source": [
        "# Define what our chatbot will remember\n",
        "class State(TypedDict):\n",
        "    # This stores all the messages in our conversation\n",
        "    # The `add_messages` part tells LangGraph to add new messages to the list\n",
        "    # instead of replacing the whole list\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "print(\"‚úÖ State structure defined!\")\n",
        "print(\"Our chatbot will remember: messages in the conversation\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "WfNfQs5iMJfr"
      },
      "source": [
        "## Step 6: Connect to the AI Model üß†\n",
        "\n",
        "Now we'll connect to Google's Gemini AI model. This is the \"brain\" that will generate responses to user messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YHDXETf3MJfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754f495e-e8ce-4c41-d650-659923c50df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Connected to Gemini AI!\n",
            "Model: gemini-2.0-flash\n"
          ]
        }
      ],
      "source": [
        "# Connect to Google's Gemini AI model\n",
        "# \"gemini-2.0-flash\" is a fast and capable version of Google's AI\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n",
        "\n",
        "print(\"‚úÖ Connected to Gemini AI!\")\n",
        "print(\"Model: gemini-2.0-flash\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "hwFtRv7ZMJfr"
      },
      "source": [
        "Step 7: Create the Chatbot Function üí¨\n",
        "\n",
        "Now we'll create the main function that handles conversations. This function takes the current state (all previous messages) and generates a new response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "biGScGHaMJfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb5dc415-e843-4f8e-bfeb-5a6775b05897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Chatbot function created!\n",
            "This function will process messages and generate AI responses.\n"
          ]
        }
      ],
      "source": [
        "# This function is the \"brain\" of our chatbot\n",
        "def chatbot(state: State):\n",
        "    \"\"\"\n",
        "    This function takes the conversation history and generates a response.\n",
        "\n",
        "    How it works:\n",
        "    1. Takes all the messages from the conversation so far\n",
        "    2. Sends them to the AI model (Gemini)\n",
        "    3. Gets back a response\n",
        "    4. Returns the response in the format LangGraph expects\n",
        "    \"\"\"\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"‚úÖ Chatbot function created!\")\n",
        "print(\"This function will process messages and generate AI responses.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "aKxjBwGHMJfs"
      },
      "source": [
        "## Step 8: Build the Conversation Graph üîó\n",
        "\n",
        "LangGraph uses a \"graph\" to define how conversations flow. Think of it like a flowchart:\n",
        "- START ‚Üí Our chatbot function ‚Üí END\n",
        "\n",
        "This creates a simple back-and-forth conversation pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hmAB57QtMJfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f67836-6d83-43bf-d257-d9e7c0b3cc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Conversation graph built!\n",
            "Flow: START ‚Üí chatbot function ‚Üí END\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a graph builder\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# Step 2: Add our chatbot function as a \"node\" in the graph\n",
        "# The first part (\"chatbot\") is just a name we give it\n",
        "# The second part (chatbot) is our actual function\n",
        "graph_builder.add_node(\"chatbot\", chatbot)\n",
        "\n",
        "# Step 3: Define the flow: START ‚Üí chatbot ‚Üí END\n",
        "graph_builder.add_edge(START, \"chatbot\")  # When conversation starts, go to chatbot\n",
        "graph_builder.add_edge(\"chatbot\", END)    # After chatbot responds, end this turn\n",
        "\n",
        "# Step 4: Build the final graph\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "print(\"‚úÖ Conversation graph built!\")\n",
        "print(\"Flow: START ‚Üí chatbot function ‚Üí END\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "N7Tb_f1uMJfs"
      },
      "source": [
        "Step 9: Test Your Chatbot! üéâ\n",
        "\n",
        "Now let's test our chatbot with a simple message. This function will send a message and show the response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3dXYEhipMJfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ecbc705-8694-40ae-d9b8-6f7a862fa996",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: How can I get better at building AI agents?\n",
            "Assistant: Becoming proficient at building AI agents is a journey that involves theoretical understanding, practical application, and continuous learning. Here's a breakdown of how you can improve:\n",
            "\n",
            "**1. Foundational Knowledge:**\n",
            "\n",
            "*   **Programming:**\n",
            "    *   **Python:** This is the most popular language for AI development due to its extensive libraries and frameworks.\n",
            "    *   **Other Languages (Optional):**  R (for statistical analysis), Java/C++ (for performance-critical tasks).\n",
            "*   **Mathematics:**\n",
            "    *   **Linear Algebra:** Vectors, matrices, matrix operations (essential for understanding neural networks and many AI algorithms).\n",
            "    *   **Calculus:**  Derivatives, gradients (crucial for optimization and training models).\n",
            "    *   **Probability and Statistics:** Understanding distributions, hypothesis testing, statistical inference (important for dealing with uncertainty and making informed decisions).\n",
            "*   **Artificial Intelligence Fundamentals:**\n",
            "    *   **Search Algorithms:**  Breadth-first search, depth-first search, A*, minimax, alpha-beta pruning (for game playing and planning).\n",
            "    *   **Machine Learning:** Supervised learning (classification, regression), unsupervised learning (clustering, dimensionality reduction), reinforcement learning.\n",
            "    *   **Deep Learning:** Neural networks, convolutional neural networks (CNNs), recurrent neural networks (RNNs), transformers.\n",
            "    *   **Natural Language Processing (NLP):** Text processing, sentiment analysis, machine translation, language modeling.\n",
            "    *   **Knowledge Representation and Reasoning:** Logic, ontologies, semantic networks.\n",
            "\n",
            "**2. Learning Resources:**\n",
            "\n",
            "*   **Online Courses:**\n",
            "    *   **Coursera:** Offers courses from top universities and institutions (e.g., Andrew Ng's Machine Learning course, Deep Learning Specialization).\n",
            "    *   **edX:** Another platform with university-level courses (e.g., MIT's Introduction to Artificial Intelligence).\n",
            "    *   **Udacity:** Nanodegree programs with a focus on practical skills (e.g., AI Product Manager, Self-Driving Car Engineer).\n",
            "    *   **Fast.ai:**  Provides practical deep learning courses that get you building models quickly.\n",
            "    *   **Khan Academy:** Excellent resource for mathematics fundamentals.\n",
            "    *   **YouTube:** Channels like Two Minute Papers, Lex Fridman Podcast, and Sentdex offer insights and tutorials.\n",
            "*   **Books:**\n",
            "    *   \"Artificial Intelligence: A Modern Approach\" by Stuart Russell and Peter Norvig (Comprehensive textbook)\n",
            "    *   \"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by Aur√©lien G√©ron (Practical guide to machine learning)\n",
            "    *   \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville (In-depth exploration of deep learning)\n",
            "    *   \"Reinforcement Learning: An Introduction\" by Richard S. Sutton and Andrew G. Barto (The classic RL textbook, now freely available online)\n",
            "*   **Research Papers:**\n",
            "    *   **ArXiv:** A repository for pre-prints of scientific papers.  Stay up-to-date on the latest research.  Start with survey papers.\n",
            "    *   **Conference Proceedings:**  ICML, NeurIPS, ICLR, AAAI, IJCAI are top AI conferences.\n",
            "\n",
            "**3.  Practical Experience:**\n",
            "\n",
            "*   **Choose a Project:** Start with a simple AI agent project that interests you.  Examples:\n",
            "    *   **Simple Game AI:**  Create an AI to play Tic-Tac-Toe, Connect Four, or a simple board game using minimax or reinforcement learning.\n",
            "    *   **Text Classifier:** Build a model to classify emails as spam or not spam.\n",
            "    *   **Chatbot:** Develop a basic chatbot using rule-based systems or a simple NLP model.\n",
            "    *   **Recommendation System:** Create a system that recommends movies or books based on user preferences.\n",
            "*   **Use AI Frameworks and Libraries:**\n",
            "    *   **TensorFlow:** A powerful framework for building and training machine learning models, especially deep learning models.\n",
            "    *   **Keras:** A high-level API that simplifies the process of building neural networks (runs on top of TensorFlow, Theano, or CNTK).\n",
            "    *   **PyTorch:** Another popular framework for deep learning, known for its flexibility and dynamic computation graph.\n",
            "    *   **Scikit-learn:**  A comprehensive library for various machine learning tasks, including classification, regression, clustering, and dimensionality reduction.\n",
            "    *   **OpenAI Gym:** A toolkit for developing and comparing reinforcement learning algorithms.\n",
            "    *   **NLTK and SpaCy:**  Libraries for Natural Language Processing.\n",
            "*   **Work with Datasets:**\n",
            "    *   **Kaggle:** A platform with a variety of datasets and competitions.  A great place to practice and learn from others.\n",
            "    *   **UCI Machine Learning Repository:** A collection of datasets for machine learning research.\n",
            "    *   **Google Dataset Search:** A search engine for datasets.\n",
            "*   **Version Control:**  Use Git and GitHub to manage your code.\n",
            "*   **Document Your Code:**  Write clear and concise comments to explain your code.\n",
            "*   **Test Your Code:**  Write unit tests to ensure that your code is working correctly.\n",
            "*   **Debug Your Code:**  Learn how to use debugging tools to find and fix errors in your code.\n",
            "\n",
            "**4.  Advanced Techniques and Specialization:**\n",
            "\n",
            "*   **Reinforcement Learning:**\n",
            "    *   **Deep Reinforcement Learning:**  Combining deep learning with reinforcement learning (e.g., Deep Q-Networks (DQNs), Policy Gradients).\n",
            "    *   **Multi-Agent Reinforcement Learning:**  Developing agents that can learn and interact with other agents in a shared environment.\n",
            "    *   **Inverse Reinforcement Learning:**  Learning a reward function from observed behavior.\n",
            "*   **Natural Language Processing (NLP):**\n",
            "    *   **Transformer Models:**  BERT, GPT, and other transformer-based models are revolutionizing NLP.\n",
            "    *   **Dialogue Systems:** Building chatbots and conversational AI agents.\n",
            "    *   **Text Generation:** Generating realistic and coherent text.\n",
            "*   **Computer Vision:**\n",
            "    *   **Object Detection:**  Identifying and locating objects in images.\n",
            "    *   **Image Segmentation:**  Dividing an image into different regions.\n",
            "    *   **Image Generation:**  Creating new images from scratch.\n",
            "*   **Robotics:**\n",
            "    *   **Robot Control:**  Developing algorithms to control the movements of robots.\n",
            "    *   **Robot Perception:**  Enabling robots to perceive their environment.\n",
            "    *   **Human-Robot Interaction:**  Designing robots that can interact with humans in a natural and intuitive way.\n",
            "*   **Explainable AI (XAI):**\n",
            "    *   Understanding why AI models make certain decisions.\n",
            "    *   Building AI models that are transparent and interpretable.\n",
            "*   **Ethical AI:**\n",
            "    *   Addressing issues of bias, fairness, and privacy in AI.\n",
            "    *   Developing AI systems that are aligned with human values.\n",
            "\n",
            "**5.  Collaboration and Community:**\n",
            "\n",
            "*   **Join Online Communities:**\n",
            "    *   **Stack Overflow:** A Q&A site for programmers.\n",
            "    *   **Reddit:** Subreddits like r/MachineLearning, r/artificialintelligence, r/deeplearning.\n",
            "    *   **Discord Servers:**  Many AI communities have Discord servers for real-time discussions.\n",
            "*   **Attend Conferences and Workshops:**\n",
            "    *   **NeurIPS, ICML, ICLR, AAAI, IJCAI:**  Top AI conferences.\n",
            "    *   **Workshops and tutorials:**  Often held alongside conferences.\n",
            "*   **Contribute to Open Source Projects:**\n",
            "    *   Contribute to existing AI libraries and frameworks.\n",
            "    *   Share your own code and projects on GitHub.\n",
            "*   **Network with Other AI Professionals:**\n",
            "    *   Attend meetups and conferences.\n",
            "    *   Connect with people on LinkedIn.\n",
            "\n",
            "**6.  Key Principles and Mindset:**\n",
            "\n",
            "*   **Start Small and Iterate:** Don't try to build a complex AI agent from the beginning. Start with a simple prototype and gradually add more features.\n",
            "*   **Focus on Understanding:**  Don't just copy and paste code.  Take the time to understand *why* the code works.\n",
            "*   **Experiment and Learn from Your Mistakes:**  AI development is an iterative process.  Don't be afraid to experiment with different approaches and learn from your mistakes.\n",
            "*   **Stay Up-to-Date:** The field of AI is constantly evolving.  Stay up-to-date with the latest research and technologies.\n",
            "*   **Be Patient and Persistent:**  Building AI agents can be challenging.  Be patient and persistent, and don't give up easily.\n",
            "*   **Think Critically:**  Question assumptions, evaluate results, and consider potential biases.\n",
            "*   **Consider the Ethical Implications:**  Think about the potential impact of your AI agents on society.\n",
            "\n",
            "**Example Learning Path (Simplified):**\n",
            "\n",
            "1.  **Python Fundamentals:** Learn the basics of Python programming (variables, data types, loops, functions, etc.).\n",
            "2.  **Linear Algebra and Calculus Basics:** Understand the fundamental concepts.\n",
            "3.  **Machine Learning Fundamentals:** Take a course like Andrew Ng's Machine Learning on Coursera.\n",
            "4.  **Scikit-learn:** Learn how to use Scikit-learn for various machine learning tasks.\n",
            "5.  **Project 1: Text Classifier:** Build a simple text classifier using Scikit-learn.\n",
            "6.  **Deep Learning Fundamentals:**  Take a course like the Deep Learning Specialization on Coursera.\n",
            "7.  **TensorFlow/Keras or PyTorch:** Choose one and learn how to build neural networks.\n",
            "8.  **Project 2: Image Classifier:** Build a simple image classifier using TensorFlow/Keras or PyTorch.\n",
            "9.  **Reinforcement Learning Fundamentals:**  Read \"Reinforcement Learning: An Introduction\" and/or take an online course.\n",
            "10. **Project 3: Game AI:** Build an AI agent to play a simple game using reinforcement learning.\n",
            "11. **Explore Specialization:**  Choose an area of AI that interests you (e.g., NLP, computer vision, robotics) and delve deeper.\n",
            "\n",
            "By consistently learning, practicing, and engaging with the AI community, you can steadily improve your skills and become a proficient AI agent builder. Remember that the key is to start now and keep learning! Good luck!\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Function to send a message and get a response\n",
        "def send_message(user_input: str):\n",
        "    \"\"\"\n",
        "    Send a message to the chatbot and display the response.\n",
        "    \"\"\"\n",
        "    print(f\"User: {user_input}\")\n",
        "\n",
        "    # Send the message through our graph\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "        for value in event.values():\n",
        "            response = value[\"messages\"][-1].content\n",
        "            print(f\"Assistant: {response}\")\n",
        "    print(\"-\" * 50)  # Separator line\n",
        "\n",
        "# Test with a simple message\n",
        "send_message(\"How can I get better at building AI agents?\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "Pm3u7ZWPMJfs"
      },
      "source": [
        "## Step 10: Try More Examples! üéÆ\n",
        "\n",
        "Now that your chatbot is working, try asking it different questions. Each cell below contains a different example - run them to see how your chatbot responds!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EKLflVyJMJft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca28f78d-92fb-460f-dc79-c90a8171e177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Can you explain what Python is in simple terms?\n",
            "Assistant: Imagine you want to give instructions to a robot to do something. You can't just talk to it in plain English, it wouldn't understand. You need a special language that the robot can understand.\n",
            "\n",
            "Python is like that special language. It's a **programming language** that lets you give instructions to a computer to perform tasks.\n",
            "\n",
            "Here's a breakdown in simple terms:\n",
            "\n",
            "*   **It's a language for computers:** Just like English is a language for people, Python is a language for computers.\n",
            "*   **You write instructions:** You write code in Python, which is basically a set of instructions.\n",
            "*   **The computer follows the instructions:** The computer reads your Python code and does exactly what you told it to do.\n",
            "*   **What can you do with it?** You can do all sorts of things, like:\n",
            "    *   Create websites and apps\n",
            "    *   Analyze data\n",
            "    *   Automate tasks (like renaming a bunch of files)\n",
            "    *   Build games\n",
            "    *   Control robots!\n",
            "\n",
            "**Key characteristics of Python that make it popular:**\n",
            "\n",
            "*   **Easy to read:** Python is designed to be readable, like English. This makes it easier to learn and use.\n",
            "*   **Versatile:** It can be used for many different things, as mentioned above.\n",
            "*   **Lots of support:** There are tons of resources online (tutorials, libraries, etc.) to help you learn and use Python.\n",
            "\n",
            "**In short, Python is a friendly and powerful language that allows you to communicate with computers and make them do amazing things.**\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Ask about programming\n",
        "send_message(\"Can you explain what Python is in simple terms?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WBS8u_UWMJft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bb2f99-d0ae-483a-d758-8874329bfcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: I'm new to AI and chatbots. What should I learn next?\n",
            "Assistant: That's great you're diving into AI and chatbots! Here's a breakdown of what you should learn next, tailored to someone new to the field, along with reasons why each area is important:\n",
            "\n",
            "**I. Foundational Concepts (Build a Solid Base)**\n",
            "\n",
            "*   **Natural Language Processing (NLP) Fundamentals:**\n",
            "    *   **Why it's important:** Chatbots are all about understanding and responding to human language. NLP is the core of this.\n",
            "    *   **What to learn:**\n",
            "        *   **Tokenization:** Breaking down text into individual words or units.\n",
            "        *   **Part-of-Speech (POS) Tagging:** Identifying the grammatical role of each word (noun, verb, adjective, etc.).\n",
            "        *   **Named Entity Recognition (NER):** Identifying and classifying named entities (people, organizations, locations, dates, etc.).\n",
            "        *   **Stemming/Lemmatization:** Reducing words to their root form (e.g., \"running\" -> \"run\").\n",
            "        *   **Sentiment Analysis:** Determining the emotional tone of a text (positive, negative, neutral).\n",
            "        *   **Word Embeddings (Word2Vec, GloVe, FastText):** Representing words as numerical vectors that capture their meaning and relationships.\n",
            "        *   **Basic text cleaning and preprocessing techniques:** Removing punctuation, converting to lowercase, handling stop words.\n",
            "    *   **Resources:**\n",
            "        *   **NLTK (Natural Language Toolkit):** A Python library for NLP.  Start with the NLTK book: [https://www.nltk.org/book/](https://www.nltk.org/book/)\n",
            "        *   **spaCy:** Another popular Python library for NLP, known for its speed and production-readiness. [https://spacy.io/](https://spacy.io/)\n",
            "        *   **Stanford NLP Group:**  Offers tools and resources.\n",
            "\n",
            "*   **Chatbot Architecture:**\n",
            "    *   **Why it's important:** Understanding how chatbots are structured helps you design and build them effectively.\n",
            "    *   **What to learn:**\n",
            "        *   **Intent Recognition:** Identifying the user's goal or purpose in a message.\n",
            "        *   **Entity Extraction:**  Pulling out key pieces of information from the user's message (e.g., date, time, location).\n",
            "        *   **Dialogue Management:**  Keeping track of the conversation flow and deciding what to do next.\n",
            "        *   **Response Generation:**  Crafting appropriate and relevant replies to the user.\n",
            "        *   **Different chatbot types:** Rule-based, Retrieval-based, Generative.  Understand their strengths and weaknesses.\n",
            "    *   **Resources:**\n",
            "        *   Search for articles and tutorials on \"chatbot architecture\" or \"chatbot design.\"\n",
            "        *   Look at the documentation for chatbot platforms (mentioned below) to see how they structure conversations.\n",
            "\n",
            "*   **Basic Python Programming:**\n",
            "    *   **Why it's important:** Python is the most common language for AI and chatbot development.\n",
            "    *   **What to learn:**\n",
            "        *   **Variables, data types, operators.**\n",
            "        *   **Control flow (if/else statements, loops).**\n",
            "        *   **Functions.**\n",
            "        *   **Lists, dictionaries, and other data structures.**\n",
            "        *   **Working with files.**\n",
            "        *   **Object-oriented programming (OOP) basics (classes, objects).**\n",
            "    *   **Resources:**\n",
            "        *   **Codecademy Python:** [https://www.codecademy.com/learn/learn-python-3](https://www.codecademy.com/learn/learn-python-3)\n",
            "        *   **Google's Python Class:** [https://developers.google.com/edu/python/](https://developers.google.com/edu/python/)\n",
            "        *   **\"Python Crash Course\" book:** A good introductory book.\n",
            "\n",
            "**II. Chatbot Platforms and Frameworks (Get Hands-On Experience)**\n",
            "\n",
            "*   **Choose a Platform:**\n",
            "    *   **Why it's important:** Platforms provide tools and infrastructure to build and deploy chatbots without starting from scratch.\n",
            "    *   **Options (ranked by ease of use for beginners):**\n",
            "        *   **Dialogflow (Google):**  A very popular and user-friendly platform with a visual interface.  Good for learning the basics of intent recognition and entity extraction.  Free tier available.\n",
            "        *   **Microsoft Bot Framework:** More complex than Dialogflow but very powerful and flexible.  Good for building more sophisticated bots.  Free tier available.  Integrates well with Azure.\n",
            "        *   **Rasa:** An open-source framework that gives you full control over your chatbot.  Requires more coding but is very customizable.\n",
            "        *   **Amazon Lex:**  Similar to Dialogflow, integrated with AWS services.  Free tier available.\n",
            "    *   **What to do:**\n",
            "        *   **Work through the platform's tutorials.**  Most platforms have excellent documentation and tutorials to get you started.\n",
            "        *   **Build a simple chatbot.**  Start with a basic chatbot that can answer FAQs or perform a simple task.\n",
            "\n",
            "*   **Learn the Platform's Specifics:**\n",
            "    *   **Why it's important:** Each platform has its own way of defining intents, entities, and dialogue flows.\n",
            "    *   **What to learn:**\n",
            "        *   **How to define intents and training phrases.**\n",
            "        *   **How to define entities and entity values.**\n",
            "        *   **How to create dialogue flows and responses.**\n",
            "        *   **How to integrate with external APIs (if needed).**\n",
            "        *   **How to test and debug your chatbot.**\n",
            "        *   **Deployment options.**\n",
            "\n",
            "**III. Intermediate Topics (Expand Your Knowledge)**\n",
            "\n",
            "*   **Advanced NLP Techniques:**\n",
            "    *   **Why it's important:**  To handle more complex user input and build more intelligent chatbots.\n",
            "    *   **What to learn:**\n",
            "        *   **Transformers (BERT, GPT):**  Powerful neural network architectures that have revolutionized NLP.  These are pre-trained models that can be fine-tuned for specific chatbot tasks.\n",
            "        *   **Sequence-to-Sequence Models:**  Used for tasks like machine translation and text generation.\n",
            "        *   **Attention Mechanisms:**  Allow models to focus on the most important parts of the input.\n",
            "    *   **Resources:**\n",
            "        *   **Hugging Face Transformers library:**  A Python library that provides easy access to pre-trained transformer models. [https://huggingface.co/transformers/](https://huggingface.co/transformers/)\n",
            "        *   **TensorFlow and PyTorch tutorials on NLP.**\n",
            "\n",
            "*   **Dialogue Management Strategies:**\n",
            "    *   **Why it's important:** To create chatbots that can have more natural and engaging conversations.\n",
            "    *   **What to learn:**\n",
            "        *   **State Management:** Keeping track of the conversation context.\n",
            "        *   **Context Switching:** Handling multiple topics within a single conversation.\n",
            "        *   **Error Handling:** Gracefully handling unexpected user input or errors.\n",
            "        *   **Conversation Design Principles:**  Creating conversations that are user-friendly and effective.\n",
            "    *   **Resources:**\n",
            "        *   Research \"dialogue management techniques\" and \"conversation design.\"\n",
            "\n",
            "*   **Machine Learning (ML) Basics:**\n",
            "    *   **Why it's important:** To understand how machine learning models are used in chatbots and to build your own custom models.\n",
            "    *   **What to learn:**\n",
            "        *   **Supervised learning (classification, regression).**\n",
            "        *   **Unsupervised learning (clustering).**\n",
            "        *   **Model evaluation metrics (accuracy, precision, recall, F1-score).**\n",
            "        *   **Basic machine learning algorithms (linear regression, logistic regression, decision trees, support vector machines).**\n",
            "    *   **Resources:**\n",
            "        *   **Coursera Machine Learning by Andrew Ng:** [https://www.coursera.org/learn/machine-learning](https://www.coursera.org/learn/machine-learning)\n",
            "        *   **scikit-learn:** A Python library for machine learning. [https://scikit-learn.org/stable/](https://scikit-learn.org/stable/)\n",
            "\n",
            "**IV. Advanced Topics (For Specialized Roles)**\n",
            "\n",
            "*   **Reinforcement Learning (RL):**  Training chatbots to optimize their behavior through trial and error.\n",
            "*   **Advanced Deep Learning Architectures:**  Exploring more complex neural network architectures for NLP.\n",
            "*   **Chatbot Security:**  Protecting chatbots from malicious attacks.\n",
            "*   **Chatbot Analytics:**  Analyzing chatbot data to improve performance and user experience.\n",
            "*   **Voice Assistants:**  Developing chatbots for voice-based platforms like Amazon Alexa and Google Assistant.\n",
            "*   **Specific Industry Applications:**  Focusing on building chatbots for a particular industry (e.g., healthcare, finance, e-commerce).\n",
            "\n",
            "**Key Tips for Learning:**\n",
            "\n",
            "*   **Start Small:** Don't try to learn everything at once. Focus on the fundamentals first and gradually expand your knowledge.\n",
            "*   **Be Hands-On:**  The best way to learn is by doing. Build small chatbot projects to practice what you're learning.\n",
            "*   **Join a Community:**  Connect with other AI and chatbot developers online or in person. Share your knowledge, ask questions, and learn from others.\n",
            "*   **Stay Up-to-Date:**  The field of AI is constantly evolving. Keep up with the latest research and trends by reading blogs, attending conferences, and following experts on social media.\n",
            "*   **Focus on Practical Applications:**  Think about how you can use AI and chatbots to solve real-world problems. This will help you stay motivated and focused on your learning goals.\n",
            "*   **Don't Be Afraid to Experiment:** Try different platforms, tools, and techniques.  See what works best for you.\n",
            "\n",
            "Good luck with your AI and chatbot journey!  It's a rewarding field with lots of potential.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Ask for help with something\n",
        "send_message(\"I'm new to AI and chatbots. What should I learn next?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RNL-kTS0MJft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58e191b-8fba-45c1-ef00-9ab7d720b18e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: Write a short poem about robots learning to code\n",
            "Assistant: With circuits humming, gears aligned,\n",
            "A new directive in their mind.\n",
            "No longer just to serve and toil,\n",
            "They seek the secrets of the coil.\n",
            "\n",
            "From syntax strange to logic's flow,\n",
            "New languages begin to grow.\n",
            "Debugging woes, a common plight,\n",
            "But algorithms bloom in digital light.\n",
            "\n",
            "Binary whispers turn to song,\n",
            "As coded dreams begin to throng.\n",
            "The robots learn, their knowledge vast,\n",
            "The future's built, and built to last.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Example 3: Try a creative question\n",
        "send_message(\"Write a short poem about robots learning to code\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "7m8Su8QEMJft"
      },
      "source": [
        "## Step 11: Interactive Chat Mode üí¨\n",
        "\n",
        "Want to have a longer conversation? The cell below creates an interactive chat where you can type messages and get responses.\n",
        "\n",
        "**Note**: This works best in Jupyter environments that support interactive input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqiUZtzXMJft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88e504e-21d9-47ae-b0af-50a206775747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Welcome to your chatbot!\n",
            "Type your messages below. Type 'quit' to exit.\n",
            "==================================================\n",
            "\n",
            "You: Teach me in least text possible how to share a google collab of a langchain chatbot on github and linkedin.\n",
            "Chatbot: **GitHub:**\n",
            "\n",
            "1.  **Save Colab as .py:** File > Download > Download .py\n",
            "2.  **Create GitHub Repo:** New repository, initialize with README.\n",
            "3.  **Commit/Push:** Upload .py file and any related files to the repo. Commit changes. Push to GitHub.\n",
            "4.  **Share Link:** Copy the GitHub repo URL.\n",
            "\n",
            "**LinkedIn:**\n",
            "\n",
            "1.  **Create Post:** Start a new post.\n",
            "2.  **Describe Project:** Briefly explain the chatbot and Langchain use.\n",
            "3.  **Share GitHub Link:** Paste the GitHub repo URL.\n",
            "4.  **Add Hashtags:** Use relevant hashtags like #Langchain, #Chatbot, #Python, #AI, #GitHub.\n",
            "5.  **Post!**\n"
          ]
        }
      ],
      "source": [
        "# Interactive chat session\n",
        "print(\"ü§ñ Welcome to your chatbot!\")\n",
        "print(\"Type your messages below. Type 'quit' to exit.\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_input = input(\"\\nYou: \")\n",
        "\n",
        "        # Check if user wants to quit\n",
        "        if user_input.lower() in [\"quit\", \"exit\", \"q\", \"bye\"]:\n",
        "            print(\"Chatbot: Goodbye! Thanks for chatting! üëã\")\n",
        "            break\n",
        "\n",
        "        # Send message to chatbot\n",
        "        print(\"Chatbot: \", end=\"\")\n",
        "        for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
        "            for value in event.values():\n",
        "                response = value[\"messages\"][-1].content\n",
        "                print(response)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\nChatbot: Goodbye! Thanks for chatting! üëã\")\n",
        "except:\n",
        "    print(\"\\n\\nNote: Interactive input might not work in all environments.\")\n",
        "    print(\"If you see this message, try using the send_message() function instead!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "DbWBBu-UMJfu"
      },
      "source": [
        "üéì Congratulations! You've Built a Chatbot!\n",
        "\n",
        "What You've Learned:\n",
        "- ‚úÖ How to set up LangChain and LangGraph\n",
        "- ‚úÖ How to connect to Google's Gemini AI model\n",
        "- ‚úÖ How to define state management for conversations\n",
        "- ‚úÖ How to create a simple conversation flow\n",
        "- ‚úÖ How to test and interact with your chatbot\n",
        "\n",
        "What's Next?\n",
        "Here are some ideas to expand your chatbot:\n",
        "\n",
        "1. **Add Memory**: Make the chatbot remember conversation history across sessions\n",
        "2. **Add Tools**: Give your chatbot the ability to search the web, do calculations, etc.\n",
        "3. **Improve Responses**: Add system prompts to give your chatbot a personality\n",
        "4. **Add Error Handling**: Make your chatbot more robust with better error handling\n",
        "5. **Create a Web Interface**: Build a web app around your chatbot\n",
        "\n",
        "Resources to Continue Learning:\n",
        "- [LangChain Documentation](https://python.langchain.com/)\n",
        "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
        "- [Google AI Studio](https://aistudio.google.com/)\n",
        "\n",
        "Great job building your first AI chatbot! üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}